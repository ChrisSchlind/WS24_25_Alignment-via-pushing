defaults:
  - defaults
  - task_factory: simple_push_task
  - camera_factory: static
  - teletentric_camera: ../teletentric_camera_config
  - _self_

log_level: DEBUG # DEBUG, INFO, WARNING, ERROR

debug: true
render: true

projection_resolution: [512, 512]

# Gripper configuration  
gripper_offset:
  translation: [0, 0, 0]
  rotation: [3.14159265359, 0, 1.57079632679]

fixed_z_height: 0.005

# Workspace bounds (in meters)
workspace_bounds:
  - [0.3, 0.9]   # x bounds
  - [-0.3, 0.3]  # y bounds
  - [-0.0125, 0.35] # z bounds

# Movement bounds (in meters)
# Movement bounds need to match the orthographic bounds of the camera
# find in teletentric_camera_config.yaml
# Center of the Camera is at x=0.6, y=0.0, z=0.1
movement_bounds:
  - [0.15, 1.05]  # x bounds
  - [-0.45, 0.45]  # y bounds
  - [-0.5, 0.5]  # z bounds


# Step size relative to the workspace bounds, old value: 0.4, now it is 1 and i like better
step_size: 1

# Movement condition
absolut_movement: True

# Reward
# Idea: Only activate one reward at a time, to see the effect of each reward
activate_distance_obj_area_reward: True
distance_obj_area_reward_scale: 2000
activate_distance_TCP_obj_reward: True
distance_TCP_obj_reward_scale: 40 #25           # Faustregel: Faktor 20-50 kleiner als distance_obj_area_reward_scale
angle_obj_area_tcp_threshold: 45.0 # in degree
activate_iou_reward: False
iou_reward_scale: 2000
activate_moves_without_positive_reward: False
max_moves_without_positive_reward: 3
activate_no_movement_punishment: False
no_movement_threshold: 0.02

# Training parameters
num_envs: 1
num_episodes: 500    #10000
max_steps_per_episode: 100 #200
batch_size: 16
target_update_freq: 100
save_freq: 10
learning_rate: 0.00005          # old value: 0.00025, trying a lower value now as the net seems to adpat too fast and be stuck at -1,-1
use_pretrained_best_model: False
auto_set_epsilon: False

# Load pretrained model
weights_dir: "models/best"
weights_path: ""

# Model parameters
model_dir: "models/dqn"
model_path: "models/dqn/dqn_episode_final"

# Plotting parameters (reward and epsilon)
plot_freq: 10
plot_dir: "models/plot"

# Parameters to determine if task is done
success_threshold_trans: 0.02
success_threshold_rot: 360.0

# Testing parameters
num_test_episodes: 10
render_delay: 50  # milliseconds between frames

# Camera settings
camera:
  image_size: [84, 84]  # Standard size for DQN input
  orthographic: true

# Supervisor settings
supervisor:
  sv_90deg_movement_threshold: 0.1      # 0.1 seems to be a good value, as most objects are smaller than 0.1m;   <0.1 is getting more aggressive with pushing and less "circling" around the object 

# Environment settings
env:
  _target_: bullet_env.pushing_env.PushingEnv  # Make sure this points to PushingEnv
  bullet_client: ${bullet_client}
  robot: ${robot}
  task_factory: ${task_factory}
  teletentric_camera: ${teletentric_camera}
  workspace_bounds: ${workspace_bounds}
  movement_bounds: ${movement_bounds}
  max_steps: 200
  coordinate_axes_urdf_path: null
#  step_size: 0.1
